import streamlit as st
from typing import List, Optional
from pydantic import BaseModel

st.set_page_config(
    page_title="LLM Chat",
    page_icon="ğŸ’¬",
    layout="wide"
)

st.title("LLM Chat Interface")

# åˆå§‹åŒ–èŠå¤©æ­·å²
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºèŠå¤©æ­·å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# èŠå¤©è¼¸å…¥
if prompt := st.chat_input("è¼¸å…¥æ‚¨çš„è¨Šæ¯..."):
    # æ·»åŠ ç”¨æˆ¶è¨Šæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # TODO: åœ¨é€™è£¡å¯¦ç¾RAGé‚è¼¯
    response = "é€™æ˜¯ä¸€å€‹æ¸¬è©¦å›æ‡‰ã€‚RAGåŠŸèƒ½å³å°‡å¯¦ç¾ã€‚"

    # æ·»åŠ åŠ©æ‰‹å›æ‡‰
    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)

# æ–‡ä»¶ä¸Šå‚³åŠŸèƒ½
uploaded_file = st.sidebar.file_uploader("ä¸Šå‚³æ–‡ä»¶", type=["txt", "pdf", "doc", "docx"])
if uploaded_file is not None:
    st.sidebar.success(f"æ–‡ä»¶ '{uploaded_file.name}' ä¸Šå‚³æˆåŠŸï¼")
    # TODO: å¯¦ç¾æ–‡ä»¶è™•ç†é‚è¼¯

class Message(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    messages: List[Message]
    context: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    sources: Optional[List[str]] = None
